// src/modules/chat/chat.ai.service.js (‚úÖ UPDATED - GRACEFUL FALLBACK)
import OpenAI from "openai";
import { Logger } from "../../shared/utils/index.js";
import { ChatResponseUtil } from "./chat.response.util.js";
import { config } from "../../config/env.config.js";

export class ChatAiService {
  constructor() {
    this.openai = new OpenAI({ apiKey: config.apiKeys.openai });
  }

  /**
   * üß† N√ÇNG C·∫§P: XU·∫§T NG·ªÆ C·∫¢NH + CHI·∫æN THU·∫¨T B√ÅN H√ÄNG THEO VAI TR√í (M·ª§C TI√äU 3)
   */
  _buildUserContextPrompt(context) {
    if (context.actorType === "User" && context.user) {
      const { displayName, email, role } = context.user;

      // --- T·∫†O CHI·∫æN THU·∫¨T B√ÅN H√ÄNG D·ª∞A TR√äN VAI TR√í ---
      const roleTactics = {
        designer: `
        [CHI·∫æN THU·∫¨T B√ÅN H√ÄNG CHO DESIGNER]
        - Ng∆∞·ªùi n√†y l√† designer chuy√™n nghi·ªáp. H·ªç quan t√¢m ƒë·∫øn:
          ‚Ä¢ Ch·∫•t l∆∞·ª£ng in (DPI, m√†u CMYK, gi·∫•y cao c·∫•p)
          ‚Ä¢ Mockup 3D ƒë·ªÉ preview
          ‚Ä¢ File ngu·ªìn (AI, PSD) ƒë·ªÉ ch·ªânh s·ª≠a
        - Chi·∫øn thu·∫≠t: ƒê·ªÅ xu·∫•t 'suggest_value_added_services' v·ªõi role='designer'
        - Tone: Chuy√™n nghi·ªáp, k·ªπ thu·∫≠t, t√¥n tr·ªçng.
        `,
        business_owner: `
        [CHI·∫æN THU·∫¨T B√ÅN H√ÄNG CHO CHU DOANH NGHI·ªÜP]
        - Ng∆∞·ªùi n√†y qu·∫£n l√Ω doanh nghi·ªáp. H·ªç c·∫ßn:
          ‚Ä¢ T·ªëc ƒë·ªô (giao h·ªèa t·ªëc 2h)
          ‚Ä¢ S·ªë l∆∞·ª£ng l·ªõn, gi√° t·ªët
          ‚Ä¢ Giao h√†ng t·∫≠n n∆°i, ƒë√≥ng g√≥i chuy√™n nghi·ªáp
        - Chi·∫øn thu·∫≠t: ƒê·ªÅ xu·∫•t 'suggest_value_added_services' v·ªõi role='business_owner'
        - Tone: Th·ª±c t·∫ø, hi·ªáu qu·∫£, t·∫≠p trung v√†o ROI.
        `,
        customer: `
        [CHI·∫æN THU·∫¨T B√ÅN H√ÄNG CHO KH√ÅCH H√ÄNG TH√îNG TH∆Ø·ªúNG]
        - ƒê√¢y l√† kh√°ch h√†ng c√° nh√¢n. H·ªç c·∫ßn:
          ‚Ä¢ Gi√° c·∫£ h·ª£p l√Ω
          ‚Ä¢ Ch·∫•t l∆∞·ª£ng ƒë·∫£m b·∫£o
          ‚Ä¢ Giao h√†ng mi·ªÖn ph√≠, b·∫£o h√†nh
        - Chi·∫øn thu·∫≠t: ƒê·ªÅ xu·∫•t 'suggest_value_added_services' v·ªõi role='customer'
        - Tone: Th√¢n thi·ªán, d·ªÖ hi·ªÉu, h·ªó tr·ª£ nhi·ªát t√¨nh.
        `,
      };

      const userTactic = roleTactics[role] || roleTactics.customer;

      return `---
NG·ªÆ C·∫¢NH NG∆Ø·ªúI D√ôNG HI·ªÜN T·∫†I (KH√îNG TI·∫æT L·ªò CHO H·ªå):
- T√™n: ${displayName || "Ch∆∞a c√≥"}
- Email: ${email || "Ch∆∞a c√≥"}
- Vai tr√≤: ${role || "customer"}
${userTactic}
---`;
    }
    return `---
NG·ªÆ C·∫¢NH NG∆Ø·ªúI D√ôNG HI·ªÜN T·∫†I:
- ƒê√¢y l√† m·ªôt kh√°ch v√£ng lai (GUEST).
- Chi·∫øn thu·∫≠t: Kh√¥ng th·ªÉ d√πng tools c·∫ßn ƒëƒÉng nh·∫≠p. T·∫≠p trung v√†o vi·ªác GI·ªöI THI·ªÜU s·∫£n ph·∫©m v√† KH∆ØY·∫øN KH√çCH ƒëƒÉng k√Ω.
---`;
  }

  /**
   * üî• ƒê√É N√ÇNG C·∫§P V·ªöI C∆† CH·∫æ "GRACEFUL FALLBACK"
   * C·ªë g·∫Øng g·ªçi v·ªõi Tool, n·∫øu l·ªói (do quy·ªÅn), t·ª± ƒë·ªông g·ªçi l·∫°i kh√¥ng c√≥ Tool.
   */
  async getCompletion(messagesHistory, tools = [], context = {}) {
    const baseSystemPrompt = `B·∫°n l√† PrintZ Assistant, tr·ª£ l√Ω AI th√¥ng minh...
    - Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán v√† chuy√™n nghi·ªáp.
    - CH·ªà S·ª¨ D·ª§NG c√°c c√¥ng c·ª• ('functions') n·∫øu c√≥.
    - KH√îNG bao gi·ªù ƒë·ªÅ c·∫≠p ƒë·∫øn "c√¥ng c·ª•".`;

    const contextualPrompt = this._buildUserContextPrompt(context);
    const finalSystemPrompt = `${baseSystemPrompt}\n${contextualPrompt}`;
    const finalMessages = [
      { role: "system", content: finalSystemPrompt },
      ...messagesHistory,
    ];

    // --- B∆Ø·ªöC 1: C·ªê G·∫ÆNG G·ªåI V·ªöI TOOL (HAPPY PATH) ---
    try {
      const completion = await this.openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: finalMessages,
        tools: tools.length > 0 ? tools : undefined,
        tool_choice: tools.length > 0 ? "auto" : undefined,
        temperature: 0.5,
        max_tokens: 350,
      });

      // TH√ÄNH C√îNG: Tr·∫£ v·ªÅ k·∫øt qu·∫£ (c√≥ th·ªÉ c√≥ tool_calls)
      return completion;
    } catch (toolError) {
      // --- B∆Ø·ªöC 2: L·ªñI (C√ì TH·ªÇ DO TOOL) -> K√çCH HO·∫†T FALLBACK ---
      Logger.warn(
        `[ChatAiSvc] L·ªói khi g·ªçi AI (c√≥ th·ªÉ do Tool): ${toolError.message}. K√≠ch ho·∫°t fallback (kh√¥ng-tool)...`
      );

      // G·ªåI L·∫†I, NH∆ØNG "NGU H∆†N" (KH√îNG C√ì TOOL)
      try {
        // T·∫°o m·ªôt System Prompt m·ªõi, ra l·ªánh cho AI kh√¥ng d√πng tool
        const fallbackSystemPrompt = `${finalSystemPrompt}\n---
        L∆ØU √ù QUAN TR·ªåNG: N·ªó l·ª±c s·ª≠ d·ª•ng c√¥ng c·ª• (tool) ƒë√£ th·∫•t b·∫°i.
        NHI·ªÜM V·ª§ C·ª¶A B·∫†N: B·ªé QUA HO√ÄN TO√ÄN vi·ªác s·ª≠ d·ª•ng c√¥ng c·ª•.
        Ch·ªâ tr·∫£ l·ªùi b·∫±ng vƒÉn b·∫£n thu·∫ßn t√∫y, th√¢n thi·ªán.
        N·∫øu ng∆∞·ªùi d√πng y√™u c·∫ßu 't√¨m ki·∫øm' (nh∆∞ t√¨m nh√† in), h√£y l·ªãch s·ª± n√≥i r·∫±ng 
        b·∫°n ch∆∞a th·ªÉ th·ª±c hi·ªán ch·ª©c nƒÉng t√¨m ki·∫øm l√∫c n√†y, nh∆∞ng b·∫°n v·∫´n c√≥ th·ªÉ tr√≤ chuy·ªán.
        ---`;

        const fallbackMessages = [
          { role: "system", content: fallbackSystemPrompt }, // Ghi ƒë√® system prompt
          ...messagesHistory, // Gi·ªØ nguy√™n l·ªãch s·ª≠ user
        ];

        const fallbackCompletion = await this.openai.chat.completions.create({
          model: "gpt-4o-mini",
          messages: fallbackMessages,
          tools: undefined, // üî• T·∫ÆT TOOL
          tool_choice: undefined, // üî• T·∫ÆT TOOL
          temperature: 0.7, // TƒÉng temp ƒë·ªÉ tr·∫£ l·ªùi s√°ng t·∫°o h∆°n
          max_tokens: 350,
        });

        // Tr·∫£ v·ªÅ k·∫øt qu·∫£ (ch·∫Øc ch·∫Øn kh√¥ng c√≥ tool_calls)
        // Agent s·∫Ω t·ª± ƒë·ªông ƒëi v√†o lu·ªìng "AI TR·∫¢ L·ªúI TH·∫≤NG"
        return fallbackCompletion;
      } catch (fallbackError) {
        // --- B∆Ø·ªöC 3: L·ªñI L·∫¶N 2 (L·ªñI TH·ª∞C S·ª∞) ---
        // N·∫øu l·∫ßn 2 c≈©ng l·ªói (v√≠ d·ª•: m·∫•t m·∫°ng, API key sai th·∫≠t)
        Logger.error("‚ùå L·ªói g·ªçi OpenAI (Fallback) API:", fallbackError);
        return this._createErrorCompletion(
          "Xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. Vui l√≤ng th·ª≠ l·∫°i sau."
        );
      }
    }
  }

  /**
   * (H√†m Vision gi·ªØ nguy√™n nh∆∞ ·ªü l∆∞·ª£t tr∆∞·ªõc)
   */
  async getVisionCompletion(fileUrl, analysisPrompt, context = {}) {
    try {
      const contextualPrompt = this._buildUserContextPrompt(context);
      const systemPrompt = `B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch thi·∫øt k·∫ø in ·∫•n.
      ${contextualPrompt}
      ${analysisPrompt}`;

      const userMessage = {
        role: "user",
        content: [
          { type: "text", text: "Ph√¢n t√≠ch file sau:" },
          {
            type: "image_url",
            image_url: { url: fileUrl, detail: "auto" },
          },
        ],
      };

      const completion = await this.openai.chat.completions.create({
        model: "gpt-4o",
        messages: [{ role: "system", content: systemPrompt }, userMessage],
        temperature: 0.3,
        max_tokens: 250,
      });

      return completion.choices[0].message.content;
    } catch (error) {
      Logger.error("‚ùå L·ªói g·ªçi OpenAI (Vision) API:", error);
      return "L·ªói ph√¢n t√≠ch n·ªôi dung file.";
    }
  }

  /**
   * (H√†m getTextOnlyCompletion ƒë∆∞·ª£c gi·ªØ l·∫°i ƒë·ªÉ d·ª± ph√≤ng)
   */
  async getTextOnlyCompletion(prompt, history = [], context = {}) {
    try {
      const contextualPrompt = this._buildUserContextPrompt(context);
      const systemPrompt = `B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch.
      ${contextualPrompt}
      ${prompt}`;

      const historyMessages = ChatResponseUtil.prepareHistoryForOpenAI(history);

      const completion = await this.openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: systemPrompt },
          ...historyMessages,
          { role: "user", content: "..." },
        ],
        temperature: 0.3,
        max_tokens: 150,
      });
      return completion.choices[0].message.content;
    } catch (error) {
      Logger.error("‚ùå L·ªói g·ªçi OpenAI (TextOnly) API:", error);
      return "L·ªói ph√¢n t√≠ch n·ªôi dung.";
    }
  }

  /**
   * Helper t·∫°o object l·ªói gi·∫£ l·∫≠p
   */
  _createErrorCompletion(errorMessage) {
    return {
      choices: [
        {
          message: {
            role: "assistant",
            content: errorMessage,
          },
        },
      ],
    };
  }
}
